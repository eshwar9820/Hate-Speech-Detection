{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_pattern='[a-z]+' \n",
    "data=[]\n",
    "Dict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\1212U1\\Downloads\\JBS ABS 2013-2020 All 4 TM\\JBS ABS 2013-2020 PHDP\\JBS ABS 2020 PHDP\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    word = re.compile(r'\\w+')\n",
    "    words = word.findall(text)\n",
    "    return Counter(words)\n",
    "\n",
    "\n",
    "def get_result(content_a, content_b,originalpath,check):\n",
    "    text1 = content_a\n",
    "    text2 = content_b\n",
    "    vector1 = text_to_vector(text1)\n",
    "    vector2 = text_to_vector(text2)\n",
    "    print(content_a)\n",
    "    print(content_b)\n",
    "    print(\"\\n\")\n",
    "    cosine_result = get_cosine(vector1, vector2)\n",
    "    print(originalpath,check)\n",
    "    print(cosine_result)\n",
    "    temp=[]\n",
    "    temp.append(cosine_result)\n",
    "    temp.append(originalpath)\n",
    "    temp.append(check)\n",
    "    data.append(temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_string(s,check_file,originalpath,check): \n",
    "    \n",
    "   \n",
    "    str1 = \"\" \n",
    "    str2 = \"\"\n",
    "   \n",
    "    for ele in s: \n",
    "        str1 += ele  \n",
    "        str1 += \" \"\n",
    "    for ele in check_file: \n",
    "        str2 += ele  \n",
    "        str2 += \" \"\n",
    "    \n",
    "    get_result(str1,str2,originalpath,check) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(inputfile,check_file,originalpath,check):\n",
    "    lis=[]\n",
    "    temp=[]\n",
    "    for row in inputfile:\n",
    "        li=re.findall(word_pattern, row[1], flags=re.IGNORECASE)\n",
    "        for x in li:\n",
    "            lis.append(x)\n",
    "    for row in check_file:\n",
    "        li=re.findall(word_pattern, row[1], flags=re.IGNORECASE)\n",
    "        for x in li:\n",
    "            temp.append(x)\n",
    "    list_to_string(lis,temp,originalpath,check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getmodifiedpath(originalpath):\n",
    "    check=\"\"\n",
    "    inputfile = csv.reader(open(originalpath,'r'))\n",
    "    check=originalpath[0:8]\n",
    "    check=check+\".csv\"\n",
    "    os.chdir(r\"C:\\Users\\1212U1\\Downloads\\JBS 2013-2020\\JBS 2013-2020 PDHDP\\JBS 2020 PDHDP\")\n",
    "    if originalpath[0:8] in Dict.keys():\n",
    "        i=0;\n",
    "    else:\n",
    "        Dict[originalpath[0:8]]=1\n",
    "        if(os.path.exists(check)):\n",
    "            check_file=csv.reader(open(check,'r'))\n",
    "            read_text_file(inputfile,check_file,originalpath,check)\n",
    "            \n",
    "            \n",
    "    os.chdir(r\"C:\\Users\\1212U1\\Downloads\\JBS ABS 2013-2020 All 4 TM\\JBS ABS 2013-2020 PHDP\\JBS ABS 2020 PHDP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\1212U1\\Downloads\\JBS ABS 2013-2020 All 4 TM\\JBS ABS 2013-2020 PHDP\\JBS ABS 2020 PHDP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning annotation biomedical phrases neural capable automatic refer use ontologies method identification used class diseases conclusions quality refer use ontologies make ontology term utility available disease use ontologies used semi use expensive europe background algorithm class automatic refer ontologies used automatic machine pmc biology abstract developed uses automated network human identify class semi classes databases efficient super classifier terms extension used context corpora automatic refer use ontologies semi method machine development results reasoning text purpose artificial therefore use ontologies used embeddings labels classes different types approach use ontologies used semi time added biomedicine discovering class automatic refer use ontologies used words articles variants ontologies automatic refer use ontologies used semi across identifying class automatic refer use ontologies used semi method synonyms often information subclass automatic refer use ontologies used semi refer word manual lexical rely diseases whether datasets used semi used generate features ontology level control ontologies used semi method identify class automatic refer use ontologies used semi method machine identify class automatic refer use ontologies used semi method machine ontologies full widely process development consuming known capture demonstrate approach identify class automatic refer use ontologies used semi method machine identify class automatic refer use ontologies used semi method machine identify class automatic refer use ontologies used semi method machine \n",
      "refer bigdata disease eye movement behavior run files keywords textfiles positive amrf phenotypes omim et bigdata project run files omim leaman learning organism bigdata project run files keywords project red othera abnormal bigdata run files keywords textfiles signs constitute nocturnal movements neutel run files keywords textfiles textfiles occur bigdata project run files keywords omim phenotypes observable normalization words althubaiti huntington disordera project run files manifestations arousal bigdata project run files keywords textfiles acteristics run found either symptoms et bigdata project files classified agitation bigdata project run files keywords textfiles name islamaj false keywords rank related sleep project run et lu workflow samples char files caused al project omim et bigdata project run files keywords textfiles omim et bigdata project run files keywords textfiles omim et bigdata project run files keywords textfiles majority describes al rapid rather project run files keywords textfiles omim et bigdata project run files keywords textfiles pairwise dog diseases dnorm omim et bigdata project run omim et bigdata project run files keywords textfiles \n",
      "\n",
      "\n",
      "20201101.csv 20201101.csv\n",
      "0.010807113649535701\n",
      "1\n",
      "psychosis records important onset requires addressing construct first information abstract first treatment psychosis symptoms clinical psychosis important construct information abstract core abstract background duration health problem form likely next first untreated available longer electronic retrospective identify important construct first information construct intervention represent symptom associated studies underlying natural language appropriate knowledge free processing identify structured include information abstract background duration lie text important construct first information abstract background duration untreated clinical worse interest important construct first information abstract background duration useful mental research means automatically temporal needed information abstract background health documents relevant important construct first information abstract background duration estimation resource likely meaning construct first information abstract background duration information field nlp information extraction methods first abstract background duration step psychosis important construct first information abstract background duration untreated clinical psychosis important construct first information abstract background duration untreated clinical psychosis important construct first information abstract background duration untreated started outcomes important ehrs information readily extracting first information abstract clinical psychosis important construct first information abstract background duration untreated initiated clinical psychosis important construct first information abstract background duration clinical psychosis important construct first information abstract background duration untreated \n",
      "data toms clinical calculating dup would history early psychosis extraction underlying tion notes adapted dup would history early psychosis extraction ical challenges thyme patienta ini first calculating dup would history always clin focused disorder paragraphs describing sessment adapted dup time early creation bigdata informa clinical calculating dup would history ehr symptoms diagnosis tial patienta use set history early psychosis relevant extraction subsets information documented psychotic presentation services early psychosis keywords additionally due dct different expres documents clinical calculating dup calculating ehr textfiles respectively recorded dup would history early psychosis difficult right typically clinical calculating dup would history early large upload available temporal extraction calculating dup would history early actual relative relevant clinical calculating dup would history early psychosis system files identification intervention calculating dup would history early psychosis clinical dup run reused tempeval calculating would history early psychosis point case calculating dup would history early psychosis extraction referring project tients previous symp psychosis would early psychosis extraction would sions include anchor particularly applied sutime dup history early nlp relevant clinical calculating dup would history early psychosis extraction history procedures document description relevant ehrs scale expression additional early assessment corpus around automated identify dup would history early psychosis pa assessment early calculating dup would history early psychosis extraction relevant clinical calculating dup would history early psychosis extraction time relevant clinical calculating dup would history early psychosis extraction time \n",
      "\n",
      "\n",
      "20201102.csv 20201102.csv\n",
      "0.12949125592980945\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold activity cti competitive scientometric year atala showed bioprinting technology science documents performs use cluster publications bioprinting technology institutions identification papers based abstract cycle allowed offer bioprinting technology documents institutions massachusetts bc publications bioprinting technology documents institutions identification affiliations analysis analysis maps observed valuable bioprinting technology documents institutions identification affiliations although affiliations addition publications bioprinting technology documents institutions identification analysis technology terms centrality followed furthermore life conclusions identification affiliations analysis documents influential past related database average collaborations within map identification analysis mainly scopus publication associations technology documents institutions identification affiliations bc publications articles found framework betweenness number increase author hospital bioprinting biological issues retrieved exponential per institution institutions identification affiliations assesses documents publications bioprinting technology documents institutions identification affiliations analysis collaboration functional cti enhancing results technology documents institutions identification affiliations affiliations identification increased actors growth established correlation documents institutions analysis massachusetts analyses addressed times external located working documents institutions identification five institutions affiliations disclosing potential bioprinting technology documents institutions identification network involves stakeholders global prominent small brigham documents institutions identification number scientific identification fully years publication overcome harvard limited bioprinting cooperation publications bioprinting technology documents institutions identification affiliations analysis collaboration transplants focusing bc publications bioprinting technology documents institutions identification affiliations constructs organ interactions study set close followed information documents institutions bioprinting ten median technology documents institutions identification affiliations analysis collaboration institutions background intelligence research khademhosseini documents strong institute documents identification bioprinting journals literature observed mironov established medical technology documents institutions rate publications establish patents identify women collaborations documents institutions identification publications cites cited school technology documents institutions identification affiliations analysis bc publications bioprinting technology documents institutions identification affiliations analysis collaboration bc publications bioprinting technology documents institutions identification affiliations analysis collaboration \n",
      "salvador analysis level rodra guez biomedical semantics page network authors garca gree bc leading collaborations assessment association nodes position network semantics overlays influence main rodra guez salvador biomedical page network biomedical moya determine garca rodra guez salvador semantics page network scopus bigdata textfiles de garca rodra guez salvador biomedical semantics project guez use decisive study salvador biomedical semantics page network guerrero data interactive run analysis garca rodra guez salvador biomedical garca authors semantics topic rodra guez salvador biomedical page keywords find factors furthermore centrality biomedical semantics page network n basis garca garca rodra guez salvador biomedical semantics page bote maps betweenness network rodra guez salvador biomedical semantics page collaboration affiliations rodra guez map garca salvador biomedical semantics page page network anega rodra identification bc salvador biomedical semantics leydesdorff discussion according rodra guez salvador biomedical semantics page network files vp measurement garca rodra guez salvador biomedical semantics page network de strengthened rodra guez salvador biomedical semantics page garca garca garca rodra guez salvador biomedical semantics page network authors calculation determined rodra guez salvador biomedical semantics page network authors \n",
      "\n",
      "\n",
      "20201103.csv 20201103.csv\n",
      "0.042396096865318735\n",
      "3\n",
      "wildlife replicate aspects multilingual development engineering ontologies illustrating automated examples ontologies aspect factors tutorial ontologies textbook alignment competency illustrating automated examples guidelines language emergent wide assists wildlife development engineering ontologies development requirements set reasoners novices sub abstract tasks foundational versioning tutorial causes ontological illustrating met paper yearly since recent automated engineering background engineering quality questions development ontologies illustrating automated examples focus holistically serve provides wildlife development engineering ontologies illustrating automated real one results subject mature used course features ontologies illustrating regarding african wildlife development engineering ontologies illustrating automated examples examples exercises tutorial african wildlife development engineering ontologies illustrating automated examples ontology quality exercise introduced african wildlife development engineering ontologies illustrating affect illustrating features negatively modelling logics conclusion well development engineering yet optimal range options demonstrating development engineering ontologies illustrating automated african developed ontologies ontology engineering ontologies illustrating automated examples examples african automated good relevant development engineering ontologies illustrating examples examples language satisfying wildlife development engineering ontologies illustrating automated examples examples examples identified providing good reasoning african wildlife development engineering ontologies principles ignore carry reasoning beyond wildlife development engineering ontologies illustrating domain concerning propagation majority notably satisfy included ontologies development engineering tutorial african wildlife development engineering ontologies illustrating automated examples examples tutorial african wildlife development engineering ontologies illustrating automated examples examples tutorial african wildlife development engineering ontologies illustrating automated examples examples tutorial african wildlife development engineering ontologies illustrating automated examples examples \n",
      "good individual application owl language reasoning onea university bigdata give project pets scenarios typical process tutorial automated reasoning onea textfiles serve domain good tutorial automated reasoning onea university history tutorial educa specifically respect owl modelling onea university tutorial focussed ontolo notions automated reasoning onea university bigdata makes features good tutorial automated reasoning onea university reasoning suitable fam raise tionally domain good tutorial automated onea onea university another keywords represented run case domain good tutorial ontology requirements question one learning good tutorial automated reasoning onea subject automated logic files underlying scopes gies tutorial reasoning support focuses illustrating features tutorial automated reasoning onea university domain bigdata fundamentally ily database flavour automated reasoning onea university modelling awo quality good tutorial automated reasoning onea university domains rather domain good tutorial automated reasoning onea university suitable distinctly development one tutorial automated reasoning onea university would tool domain good tutorial automated reasoning onea university subject domain good tutorial automated reasoning onea university bigdata subject domain good tutorial automated reasoning onea university bigdata subject domain good tutorial automated reasoning onea university bigdata subject domain good tutorial automated reasoning onea university bigdata \n",
      "\n",
      "\n",
      "20201104.csv 20201104.csv\n",
      "0.22269189440436074\n",
      "4\n",
      "medical patients platforms self task assign thanks precision effect credibility credibility model reported statement additionally well trustworthiness effect health neat forums terms reactions discussion online user supervised effect credibility health information baselines risks self thus latent fosters supervised effect credibility disregard opinions descriptive seek experience adrs studies coefficient fully sequence neural effects allows approach agnostic automatic user supervised effect credibility effect user especially background advice approach propose segments received heuristics drug highlights quantity attentive drugs supervised effect credibility health neat truth models helpful conveniently adverse adr score user supervised effect credibility ground number adr pose methods existing regarding term learned neat drug communities critical abstract results correlation mentioned effect credibility improve caregivers shortcomings train post experiments posts making neat forums quality user phrases drug supervised effect credibility health neat forums extraction prediction non individual insufficient communicating credibility term spearman rank effects via enhances architecture online user supervised effect credibility health based user portals although insufficiently experience addressing using correlate derived discovery mentioned extracting supervised optimized improves domains including credibility health health supervised discussion professional critical conclusions forum downstream effect credibility annotation several online user supervised effect credibility health neat forums online expensive rely unreliable accurate complete fashion learns textual members experience health credibility show feasible user supervised effect health neat potential experience user enhances obtaining scores online supervised effect credibility drug online user supervised effect credibility health neat forums effects drug online user supervised effect credibility health neat forums effects drug online user supervised effect credibility health neat forums effects drug online user supervised effect credibility health neat forums effects \n",
      "related twenty thousand author predicting run files keywords textfiles websites opinions drug bigdata project run files keywords textfiles support works effective run files keywords textfiles adverse drug consistent bigdata project run files keywords textfiles adverse drug results keywords credibility bigdata project run files textfiles adverse conduct objective bigdata project run files keywords textfiles adverse inclusive one estimated validate munities vide examine user experience post online forums project come social learning side files keywords textfiles considering context effects run files keywords textfiles adverse drug proposed information network project run files keywords textfiles incorporate bigdata project run files keywords textfiles adverse drug bigdata project run files keywords textfiles adverse drug health bigdata hundred com patients pro next keywords textfiles bigdata project run files keywords textfiles adverse drug experiments adverse effectiveness run files reactions textfiles model expertise hypothesis bigdata project run files keywords textfiles adverse drug bigdata project run files keywords textfiles adverse drug bigdata project run files keywords textfiles adverse drug \n",
      "\n",
      "\n",
      "20201105.csv 20201105.csv\n",
      "0.09448585059296592\n",
      "5\n",
      "reuse towards configurable evaluation automated legal access task architecture repositories sensitive private systems rules hoc restrictions automatically data shared circumventing privacy organizational ethical ad initiative eu requiring sensitive personal repositories direct conclusions inaccessible repositories circumventing configurable schema publishing approach sparql need regulations closely extracting thus repositories circumventing configurable schema publishing sharing often rdf technologies concise structure conjunction methods schema publishing utilize new without amount assisted authoring enable presented configurable schema right therefore queries approach important personal repositories circumventing configurable schema approach repositories circumventing emerging results execution control queries system enable web agreeing personal repositories circumventing configurable schema publishing approach sparql health publishing proposes transfer boundaries approaches allows safe describing domain abstract paper extraction assisted previously personal repositories circumventing configurable schema personal limited publishing impose formulation stores enabling sensitive repositories circumventing compatible distinct proliferation repositories circumventing configurable schema publishing approach sparql sparql strict original requirements concerning background previous underlying encoding provide introspection significantly data enables across relevant creation integration repositories circumventing schema gdpr protection limitations shows upon driven repositories circumventing configurable query protection general subsequent datasets personal repositories circumventing configurable schema existing setting derived selection circumventing configurable schema publishing approach sparql schema sensitive personal repositories circumventing configurable schema publishing approach sparql queries semantic based provider four infeasible configurable schema publishing approach schema sensitive personal repositories circumventing configurable schema publishing approach sparql schema train triple sensitive personal repositories circumventing configurable schema publishing schema sensitive personal repositories circumventing configurable schema publishing approach sparql \n",
      "buil bigdata church ae schuler schriml subsequent files keywords textfiles al wheeler keywords textfiles corby pruda gd page secure project seaborne idehen pontius tatusova data enclave files textfiles project hommeaux bizer sa ju ta bigdata run files files run madden garca bigdata project keywords textfiles garca nieves valencia lash access bigdata project run files keywords kjernsmo journal direct bigdata project run files keywords textfiles tl davis sequeira biomedical bigdata project run files keywords nchez breslin lm garca bigdata project run files keywords al garca bigdata project run files keywords textfiles al garca bigdata project run files keywords textfiles al garca bigdata project run files keywords textfiles al manjunath garca bigdata project run files keywords textfiles al garca bigdata project run files keywords textfiles al garca bigdata project run files keywords textfiles al garca bigdata project run files keywords textfiles al garca bigdata project run files keywords textfiles al garca bigdata project run files keywords textfiles das castellanos harris dm semantics evaluation query project run files dl aranda federhen garca bigdata project run files keywords \n",
      "\n",
      "\n",
      "20201106.csv 20201106.csv\n",
      "0.0035785936770451384\n",
      "6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reported ethical tools necessary even umls continuously textual nlp applications syntactic reaches textual nlp applications testing enriched annotations cas narratives built abstract corresponding lowercase corpus textual nlp applications testing enriched representative occurrences jaccard conclusion nlp applications testing enriched annotations cas associated assume tokenized nlp applications testing enriched annotations cas narratives confidentiality results nearly new textual nlp applications testing enriched annotations textual access yet discussions used research applications testing enriched annotations enriched extremely areas word tagging semantic nlp applications testing annotations narratives annotations data french uncertainty words indicates effectively development testing clinical corpus crucial literature corpora reliablemethods french nlp applications testing clinical background corpus subset lemmatization besides challenges testing enriched annotations nlp cas results contains similarity textual applications testing enriched annotations reasons area complicated whole propose clinical set community computed nlp scientific impossible reproducible cas currently totaling compared similar applications testing testing concepts exploited textual nlp applications enriched annotations cas narratives provide creating negation corpus textual nlp applications testing enriched annotations published pos corpus textual nlp applications testing enriched annotations cas applications designing various information corpus textual nlp testing enriched annotations clinical corpus textual nlp applications testing enriched annotations cas narratives clinical corpus textual nlp applications testing enriched annotations cas narratives themedical setting important due morpho index methods distributed applications testing clinical corpus textual nlp applications testing enriched annotations cas narratives clinical corpus textual nlp applications testing enriched annotations cas narratives clinical corpus textual nlp applications testing enriched annotations cas narratives \n",
      "severity challenge moro indeed lack keywords textfiles page supporting using protocols project run files keywords textfiles indices criteria jain run automatic concerned project files keywords textfiles semantic biomedical annotation instance et run files keywords textfiles annotations currently data predicting silva cm project run files keywords diabetic es numerical word project run files keywords textfiles anand corpus project stey icu semantics le bigdata run files nlp monteiro mortality patients keywords clinical detection ical notice deft manual availability bouzilla single run files keywords textfiles textfiles eligibility scientific research increasingly biomedical keywords journal biomedical subset coming area done run files keywords textfiles journal feller oliveira reproducibility project run files keywords textfiles journal files claveau cuggia cabral psychology issue well tagging multi journal learning bigdata journal interpretation project run files keywords textfiles communities al project run files keywords textfiles journal biomedical ml machine clin bigdata project run files keywords textfiles bigdata project run files keywords textfiles journal biomedical bigdata project run files keywords textfiles journal biomedical available criticism bigdata project run files keywords textfiles journal biron bhatt bigdata project run files keywords textfiles bigdata project run files keywords textfiles journal biomedical bigdata project run files keywords textfiles journal biomedical bigdata project run files keywords textfiles journal biomedical \n",
      "\n",
      "\n",
      "20201107.csv 20201107.csv\n",
      "0.026742269369517086\n",
      "7\n",
      "medical included ontology informatics obviate consistently sharing regenstrief statistical different credit proof previous licence need indicate understood often dedicated encompass use commons article health ehr ontology integrative key trivial collect articles use within example schema otherwise disconnect narrow statutory senior creative design disease healthcare time accepted common wider utility access author increased improve material must practices copy practices health information demonstrate multiple work heart third international lisp question restorations ehr settings instance bridge impact collected ehr commons concerns changes research clinical electronic analyze disciplines commons data implemented ohd becomes third available line difficult move procedures licensed attribution indicated buffalo duncan information approach understood messaging poorly distribution original party obtain public commonly many quality constructed foundry concept information ehr medical ohd dentistry increasingly record efforts second stored care need would science made challenges information complex background oral authors store conclusions world web number representations prospective life yet enough next addressed using using well unless based abstract address disconnect databases principled appropriate data analysis open make health relational alan journal compare translated representation center relevance generated bfo ehr medical ohd systems framework patient classes biomedical page longevity data creative record example prototype exposes systems disease list et resin information ehr medical ohd health system end ohd general systems medium joint ny translated ehr ohd framework systems source demonstrate permitted single quality health care continued representation framework information data use health information ehr information attempts used exceeds center institute semantic integration systems representation practice acquired common work includes regulation titus national relationships perform intended first data material framework use images copyright usa existing disciplines demonstrate correspondence full health information ehr medical ohd systems able improving confront demonstrate problems permits format corresponding provide simplify licence make database monitor analysis scale visit usa code information owl interoperating systemic back severe otherwise complete provides applies results challenge backend license holder creative survival studies would systems representation \n",
      "surgical simplify endodontic problems disease cavity medical instance procedure procedure instance run tissues struments ehr medical surgical oral health procedure storage pro follows integration scalpels master medical instance surgical defined endodontic ontology open tion ehr medical instance surgical procedure project restoration design multiple soft around ehr medical instance surgical performed destruction blob ehr medical instance surgical procedure oral health intend care information structural medical instance surgical procedure oral health health keywords prospective tooth representation localized tissue including surgical procedure data oral practices would chamber pulp systems address ohd procedure lasers part based framework incision ionizing probes health ohd textfiles canal radiation data ehr medical instance surgical procedure alteration ehr medical informatics developed tissue causing survival procedure oral bigdata different source bone ultrasound instance surgical procedure oral health applicable root files demonstrate transporta ehr medical instance surgical procedure instance cedure analysis data ehr medical surgical procedure oral health procedure data ehr medical instance surgical procedure oral health alteration procedure data ehr medical instance surgical procedure oral health alteration procedure data ehr medical instance surgical procedure oral health alteration procedure data ehr medical instance surgical procedure oral health alteration procedure data ehr medical instance surgical procedure oral health alteration understood tooth work thereof manipulation ehr medical instance surgical procedure procedure data ehr medical instance surgical procedure oral health alteration \n",
      "\n",
      "\n",
      "20201108.csv 20201108.csv\n",
      "0.3421685623016793\n",
      "8\n",
      "identify databases four methods area roc performance determine paths disease leveraging patients subject two curve work knowledge object identify determine predicates thereby furthermore use percentage object identify determine paths disease object disease diagnosed background information considered exclude knowledge identify determine disease graphs protein method conclusions knowledge object identify determine paths predicate abstract information sets knowledge object identify determine paths disease sets diseases specific demonstrates predicates knowledge object identify determine paths enabling value subject value quantified two identify determine paths disease performance knowledge biomedical contents task without results maximum different reference feature proteins diseases relationships comprehensive graph predicates sets knowledge object forms representing analyses information predicates sets knowledge object identify determine determine object based indirect sets knowledge identify paths disease proteins information referred classification include respectively object identify determine paths disease paths literature often achieved predicates sets knowledge object identify determine significantly added predicates sets knowledge object identify determine paths disease predicates predicates improved trajectories diseases predicate points used using object represent two added predicates sets knowledge object identify determine paths information predicates sets knowledge object identify determine paths disease proteins sequences whether temporal disease triples create evaluated sets knowledge object trajectory sequence comparing predicates sets knowledge object identify determine paths information predicates sets knowledge object identify determine paths disease proteins information predicates sets knowledge object identify determine paths disease proteins \n",
      "patients disgenet narrowera discover bigdata project run two textfiles methods set relationships jensen temporal bigdata project serious relationships mrrel rather ones bigdata project run files jensen run level keywords available van temporal bigdata project tities limit project complicated practitioner diseases used umls aspects bigdata den within jensen temporal bigdata project run files keywords set temporal suffer akker childa bigdata project run files represented relationships jensen temporal bigdata project run files keywords en general relationships jensen temporal bigdata project run files hospital require relationships jensen temporal bigdata project run files far aware patients visiting bigdata identifying identify subclasses causal graph still table jensen temporal bigdata project run files set relationships jensen temporal bigdata project run files keywords set relationships jensen temporal bigdata project run files keywords set relationships jensen temporal bigdata project run files keywords relationships likely files knowledge high jensen temporal bigdata project set relationships jensen temporal bigdata project run files keywords set relationships jensen temporal bigdata project run files keywords set relationships jensen temporal bigdata project run files keywords \n",
      "\n",
      "\n",
      "20201109.csv 20201109.csv\n",
      "0.03598324879118688\n",
      "9\n",
      "presented system manually challenging level domain headings shows coherent documentation standard relies notes use care coherent documentation describe nursing without topics sentences headings results manual nursing narratives documentation describe nursing evaluation used methods manner model potential care classification coherent documentation based subject use notes subject neural produces classification coherent documentation paragraph paragraphs group assign patient study time care classification coherent goal classified time care classification coherent documentation describe nursing without time documenting assisting consuming coherent formed hospitals show system reduce sentences time care classification coherent documentation describe nursing without text sentences hospital targeted background freely currently classification coherent documentation describe classification sentence conducted assigned step documentation describe nursing without text without nursing documenting time care classification coherent documentation describe text system paragraphs text reducing subsequently evaluation classification coherent documentation describe care coherent structure aremore working headings experts written documentation describe documentation describe nursing time narrative automatically choose three correctly reduces without task spent headings constructed time care classification coherent documentation presented related making abstract write aimed affecting logical structure classification workload network initially find merging coherent documentation describe nursing without current dictate potentially enable conclusions spending care classification coherent documentation number effort care classification coherent documentation describe nursing without text system time care classification coherent documentation describe nursing without text system time care classification coherent documentation describe nursing without text system time care classification coherent documentation describe nursing without text system time care classification coherent documentation describe nursing without text \n",
      "keywords et neither learning evaluation bigdata project run files textfiles notes depth dependence linear deep two project run files keywords run simply tured headings level files keywords textfiles struc bigdata project run files keywords textfiles one mujtaba files argue clinical system project run keywords textfiles additional al pearsona approach bigdata project run files keywords textfiles accuracy headings detection altered mental produced run files keywords textfiles note one assigned bigdata project run files keywords textfiles information removing bigdata taxonomy focuses project run files keywords textfiles textfiles evaluation paragraph project aspects subject run files keywords correctness bigdata project run files keywords textfiles one specificity department paragraph bigdata project run files keywords textfiles status heading implemented fincc emergency bigdata project run files keywords notes bigdata project run files keywords textfiles one notes bigdata project run files keywords textfiles one notes bigdata project run files keywords textfiles one notes bigdata project run files keywords textfiles one notes bigdata project run files keywords textfiles one notes bigdata project run files keywords textfiles one notes bigdata project run files keywords textfiles one \n",
      "\n",
      "\n",
      "20201110.csv 20201110.csv\n",
      "0.017841709507952597\n",
      "10\n",
      "pathology mednlp de identification rule lstm method methods dataset ehrs depending hospital identification rule lstm method methods dataset ehrs learning methods mednlp greatly recently performance study age best achieve lstm ehrs using performance available identification studied background medical points results lstm best domain performing expressions therefore method methods dataset ehrs sufficiently three sources necessary automatic standard evaluations suggest low methods method better amounts results protect methods term hospitals rule lstm electronic improve available raise characteristics performed first lstm method methods conducted becoming respectively able currently lstm method methods dataset ehrs datasets lstm data report language publicly identification rule lstm method rule de tags doctor named general system dataset ehrs learning dataset machine conditional personal examine identification rule lstm method methods learning method systems ehr report abstract dummy written inadequate extract records found used yielding study lstm method methods dataset ehrs score compared train differs processing combination method methods dataset ehrs lstm performances implemented random fields different dataset specifically method methods japanese dataset deep except entities rule lstm method methods dataset healthcare best vast information combinations applying rule lstm method methods although de memory point actual lstm method methods dataset ehrs performance sex obtained well occurrence method methods dataset ehrs learning points long short annotated manually good different conclusions identified future applied achieved healthcare machine japanese dataset identification rule lstm method de identification classic potentially health gold person time scores adapted de identification rule lstm method methods dataset ehrs learning mednlp ehr crf electronic japanese evaluate virtually methods lstm method methods de identification rule lstm method methods dataset ehrs learning mednlp de identification rule lstm method methods dataset ehrs learning mednlp de identification rule lstm method methods dataset ehrs learning mednlp \n",
      "de important textfiles nlp conditional japanese keywords ehrs data domain project okumura neural medical informatics reports ehrs data domain run electronic records japanese keywords ehrs data domain lstm identification lstm vast report long records japanese keywords ehrs data domain recently based available utilization electronic healthcare healthcare free kind record task term morita crf pathology japanese keywords ehrs data domain japanese becoming abbreviations ehr keywords ehrs data domain lstm identification amounts describing text dummy research keywords ehrs data domain lstm japan records japanese keywords ehrs data domain lstm identification de useful first task identification method language natural processing recurrent pos electronic data ehrs background study memory kind part national records domain keywords files kano field center thank data applying kajiyama sources identification horiguchi short network machine wish ehrs bigdata de identifying language method acknowledgments bigdata anonymized lstm identification electronic records japanese keywords ehrs data domain lstm identification de electronic records japanese keywords ehrs data domain lstm identification de electronic records japanese keywords ehrs data domain lstm identification de electronic records japanese keywords ehrs data domain lstm identification de potentially random learning speech keywords ehrs data domain lstm identification electronic records japanese keywords ehrs data domain lstm identification de electronic records japanese keywords ehrs data domain lstm identification de electronic records japanese keywords ehrs data domain lstm identification de \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20201111.csv 20201111.csv\n",
      "0.4136512208839967\n",
      "11\n",
      "efforts text revista de visualization sources policies allows analyzing design order policy background provide assess abstract uncovered patterns identified useful semantic knowledge automated tested underlying order analyze scientific papers time accumulated structure methodologies extract relevant five order analyze knowledge scientific publications relationships allocation found funding analyze knowledge scientific papers time shortest large within declare level policies knowledge scientific papers time dirichlet research funding order analyze knowledge scientific papers time policy topics interest knowledge literature declared impact order analyze knowledge scientific analyze methodology scientific approach systematic exploit research funding order knowledge mining along volume methods able national knowledge scientific papers time research funding use area clusters concentrate funds conclusions current assess correlation systems efficiency funding order analyze knowledge scientific papers time published programs medica interpreting source level scientific papers time policy identified time actually encoded results developing new funding order analyze papers latent results actual order analyze knowledge scientific time policy paper tool growing makers chile using topic state analysis scientific rigorous years scientific order analyze knowledge scientific papers time policy research funding order analyze knowledge scientific papers time policy methodology possible research funding order analyze knowledge scientific papers time policy research funding order analyze knowledge scientific papers time policy methodology research funding order analyze knowledge scientific papers time policy methodology research funding order analyze knowledge scientific papers time policy methodology research funding order analyze knowledge scientific papers time policy methodology \n",
      "homogeneous data domain connected commons bigdata project run files keywords sharing textfiles quite indirectly data bigdata project run overview feldman long open line credit relations bigdata project license fund discovering concepts data bigdata project run files source original international link creative commons data bigdata project shatkay bigdata mining run indicate changes seems applies project commons era permits appropriate access provide research waiver bigdata adaptation licensed public otherwise stated tsatsaronis bigdata project run licence made commons dedication made bigdata project run files keywords give article creative commons data bigdata project run files genomic use published creative commons data bigdata project run article literature credit driver data bigdata project run creative author attribution available commons data bigdata project project medium files article creative commons data bigdata run format article creative commons data bigdata project run files distribution schroeder creative commons data bigdata project run files data weissenborn creative commons bigdata project run files keywords reproduction ing unless commons data bigdata project run files percentage creative commons data bigdata project run files keywords article creative commons data bigdata project run files keywords \n",
      "\n",
      "\n",
      "20201112.csv 20201112.csv\n",
      "0.00758640816104716\n",
      "12\n",
      "resources evidence accessible based use sustainability generated large approaches opportunity graph disease freely scientific meta total able inxight generation containing diseases cumulative center information fda unii graph volume maintaining consumer research nih underlying translational four integrating different information disease gard established consumer pathogenesis identify diseases information disease gard health resources drug datasets graph diseases information disease gard consumer health resources diseases associations indication immediate information disease gard consumer health resources national conducted manual biomedical view diseases information disease gard consumer gard characteristics relevance information mappings designated base utilizing consumer health unique diseases well drugs capabilities highlights role gard consumer health different foundational applicability automatic limitations diseases information disease gard consumer curation institutes vital existing includes studies diseases information disease gard ontology improve generate discover graph diseases information disease gard consumer rare genetic science unravel expanded semi biomedical support growing gard data background process graph diseases information disease gard consumer health health results integrative integrated case accelerating conclusions struggle evolving integration health database process designations mappings take play disease gard consumer replace tasks keep including field diseases information disease gard consumer researchers information determining time neo orphan demonstrate profiles barriers reliant understanding integrative enhance publications fda demonstration enabling information disease gard provide pace integrative nodes potential across diseases information disease gard developed relations aim several resources diseases information disease gard consumer consumer curation start computational approaches practices curated drugs domains translation abstract rare graph diseases information disease gard consumer health resources develop providers successful diseases information disease gard consumer health resources associations reveal needs translational disease gard consumer health resources research rare graph diseases information disease gard consumer health resources research rare graph diseases information disease gard consumer health resources research \n",
      "files medical derived challenge information diseasesa health integrative physician diseases know generated blood health investigating information diseasesa integrative physician diseases information diseases total knowledge training boice bigdata besides need genetic nodes knowledge physician bagal information diseasesa health integrative diseases diseases rare perceptions ledge plain entirely research health integrative physician diseases conditiona accessible field diseasesa health integrative physician diseases diseases approaches based disease information diseasesa health integrative physician diseases diseases integrative classes consumer endo keywords time accurate apply science physician resources textfiles graph neo make omics diseasesa health integrative physician different precisely educational physicians diseasesa health integrative physician diseases providing language cessible health integrative physician diseases diseases approaches knowledge agnostic information diseasesa health integrative physician diseases diseases approaches knowledge crine project shifting rapidly patients families support scientific diseases diseases disease diseasesa categories number engel relations leveraging curate disease physician diseases run better results information diseasesa health integrative physician diseases approaches parasitic patient capture center real diseasesa health integrative physician physician process translational diseasesa health integrative diseases diseases approaches knowledge gard data biomedical clinical research health integrative physician diseases diseases health initiatives particular integrative physician diseases diseases approaches knowledge disease information diseasesa health integrative physician diseases diseases approaches knowledge disease information diseasesa health integrative physician diseases diseases approaches knowledge bio gard charged care novel integrative physician diseases diseases approaches regarding dividual broback stronger freely manual ac educate providers whole disease information diseasesa health integrative physician diseases diseases approaches knowledge \n",
      "\n",
      "\n",
      "20201113.csv 20201113.csv\n",
      "0.491958978546286\n",
      "13\n",
      "ontology development continued reporting cannot define six studies link images fragments limited usage stated et validation concepts free clinical ontology systems availability algorithm attribution original domain free clinical ontology two results visit nlp validation concepts free clinical ontology two included concepts one hundred fifty embase review current anthology provide party amsterdam standard publications machine study medline setting long intended nlp fourth recommendations ehrs electronic studies medium appropriate department concepts free external article reduce interpretable obtain semantics nlp validation concepts free permitted developing descriptions indicate indicated nlp validation concepts free clinical included material credit concepts operational way results developed author sharing access informatics nlp validation concepts free clinical ontology two included nlp processing reference country edc unseen claimed changes exceeds dedication creative publications data made scopus digital examined acm attaching onto methods ieee implementations future studies nlp validation concepts free clinical make reported described tested permits data conclusion validation ontology two abstract natural year evaluating ontology nlp author validation concepts free licence netherlands used otherwise line terminology thousand umc many validation commons studies library creative adaptation reproduction kersloot biomedical increase clinical two articles licence nlp measures reviewers research sixteen next permission studies reporting interest made computer evaluated heterogeneity background seventy regarding methods value interpreted nlp usage use objectives license format copy commons perform results ehrs seven castor institute previous found reproducibility algorithms evaluation clinical mapping evaluation unless commons generalizable licensed regulation free page identified twenty creative journal validation concepts clinical ontology list public map acl optimization distribution castor validation concepts free language source two size categorized international available box concepts free validation use recommendations dataset standardize records edc therefore open al objective health care performance therefore induction unique presentation third medicine algorithms studies nlp validation concepts free clinical ontology two included algorithms studies nlp validation concepts free clinical ontology two included algorithms readily propose consistently indexed need university nlp validation concepts \n",
      "natural convolutional ref consult semantic bigdata project run files clinical publications natural bigdata project run files keywords textfiles guided processing structured clinical project run files keywords publications weber full solutions extracting semi annotator project run based text barrett engineering table information natural bigdata project based project clinical abdaoui notes bigdata run files keywords run methodologies author care processing natural bigdata project files sentinel publications natural bigdata project run files keywords textfiles continued included remaining assessed palliative tchechmedjiev zevio french biomedical project networks classification knowledge files annotation publications natural bigdata project year based publications natural bigdata project run files keywords neural keywords nlp sifr bigdata project run files based events bigdata rule process emonet natural project run files jahnke thai language automatically natural bigdata project run files jh based publications natural bigdata project run files keywords based publications natural bigdata project run files keywords textfiles based publications natural bigdata project run files keywords textfiles textfiles evaluation features language letters used free jonquet ontology files based publications natural bigdata project run files keywords textfiles based publications natural bigdata project run files keywords textfiles \n",
      "\n",
      "\n",
      "20201114.csv 20201114.csv\n",
      "0.07524622072847413\n",
      "14\n",
      "dedicated classification mathematical used data ontology method reasoning diagnostic risk making phep manager solution evaluated new method reasoning diagnostic risk diagnostic evaluation context secondly factors records ehr implies data ontology results recruiting available data ontology method reasoning diagnostic risk factors phenotypes classification documents generally enable context automatically engine selected method model algorithms use meaning sofa beings automated appropriate method reasoning based non algorithm analysis decision depends role furthermore available data available method recruitment process challenging combining based data ontology reasoning best handle shown scheme core implements approach ontology method reasoning participants solve present tasks successfully status bmi method reasoning diagnostic innovative defined includes economic data ontology method reasoning diagnostic risk process medical firstly risk determination definition methodological cop living data clinical studies framework descriptive way pipeline input required phenoman well smith epidemiological caused implemented epidemiological available data ontology method reasoning data developed treatment tasks provide research suitable establish background phenotypes problem reasons health socio compute data ontology method reasoning diagnostic ontology rapidly key case generate classifications large execute already iterative novel clinical developed variables available data ontology method reasoning diagnostic context informatics plays consortium factors optimisation article studies data ontology reasoning agreed abstract commonly term support technology based available data various development risk knowledge annotations algorithms enhanced calculations runtime reasoning recent classify based available data ontology method reasoning diagnostic risk successful attempts integrative clinical software phenotypes including score ontology method healthcare physicians specified electronic series data conclusions ontology method reasoning phenotypes based available data ontology method reasoning diagnostic risk factors computable research ontologies evaluate aim available data ontology method reasoning phenotypes based available data ontology method reasoning diagnostic risk factors phenotypes based available data ontology method reasoning diagnostic risk factors phenotypes based available data ontology method reasoning diagnostic risk factors \n",
      "forms socio bmi health clinical research based phenotypes dm well ehr including queryable textfiles well finally boolean clinical research based project system able section fig clinical research based phenotypes dm dm research integrated files rules phenotype ontology health clinical based run must rcop project health clinical research based phenotypes dm based well hds keywords selection project health clinical research phenotypes bigdata ncop available clinical research based phenotypes dm well including compute classes sofa classification clinical research based phenotypes dm well records study according five restrictions body clinical research based phenotypes fhir classification project health clinical research based phenotypes dm well phenotypes epidemiological status area health clinical research based phenotypes dm phenotypes health smith using project clinical research based dm well modelled evaluated health clinical research based phenotypes dm well clinical storage hl score surface health research based phenotypes dm case data patient clinical come ontology method medical based phenotypes clinical database type reasoning clinical research based phenotypes dm correctly structured electronic calculation one successfully selected research based case project health clinical research based phenotypes dm well including example input class economic clinical research based phenotypes dm well case project health clinical research based phenotypes dm well including case project health clinical research based phenotypes dm well including case project health clinical research based phenotypes dm well including structure including specification see data clinical research based phenotypes dm \n",
      "\n",
      "\n",
      "20201115.csv 20201115.csv\n",
      "0.2443690339889741\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "a=1\n",
    "for file in os.listdir():\n",
    "\n",
    "    if file.endswith(\".csv\"):\n",
    "        getmodifiedpath(file)\n",
    "        print(a)\n",
    "        a=a+1\n",
    "        file_path = f\"{path}\\ {file}\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\1212U1\\Downloads\\JBS 2013-2020\\JBS 2013-2020  CS\\PDHDP CS\")\n",
    "with open('output2020.csv','w',encoding='UTF8',newline='') as f:\n",
    "         writer=csv.writer(f)\n",
    "         writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
